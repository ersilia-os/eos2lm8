{
    "Identifier": "eos2lm8",
    "Slug": "smiles-transformer",
    "Status": "Ready",
    "Title": "SMILES transformer descriptor",
    "Description": "Molecular embedding based on natural language processing. It converts SMILES into fingerprints using an unsupervised model pre-trained on a very large SMILES dataset from ChEMBL. The transformer is particularly well-suited for low-data drug discovery.",
    "Deployment": [
        "Local"
    ],
    "Source": "Local",
    "Source Type": "External",
    "Task": "Representation",
    "Subtask": "Featurization",
    "Input": [
        "Compound"
    ],
    "Input Dimension": 1,
    "Output": [
        "Value"
    ],
    "Output Dimension": 1024,
    "Output Consistency": "Variable",
    "Interpretation": "Vector representation of small molecules",
    "Tag": [
        "Chemical language model",
        "Descriptor",
        "Embedding"
    ],
    "Biomedical Area": [
        "Any"
    ],
    "Target Organism": [
        "Any"
    ],
    "Publication Type": "Preprint",
    "Publication Year": 2019,
    "Publication": "https://arxiv.org/abs/1911.04738",
    "Source Code": "https://github.com/DSPsleeporg/smiles-transformer",
    "License": "MIT",
    "Contributor": "miquelduranfrigola",
    "Incorporation Date": "2021-09-28",
    "S3": "https://ersilia-models-zipped.s3.eu-central-1.amazonaws.com/eos2lm8.zip",
    "DockerHub": "https://hub.docker.com/r/ersiliaos/eos2lm8",
    "Docker Architecture": [
        "AMD64",
        "ARM64"
    ],
    "Model Size": 22.0,
    "Environment Size": 2301.0,
    "Image Size": 2283.39,
    "Computational Performance 1": 33.65,
    "Computational Performance 2": 24.23,
    "Computational Performance 3": 31.5,
    "Computational Performance 4": 177.36,
    "Computational Performance 5": 842.08
}