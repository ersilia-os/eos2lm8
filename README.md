# SMILES transformer fingerprint

## Model Identifiers
- Slug: smiles-transformer
- Ersilia ID: eos2lm8
- Tags: fingerprint,	NLP,	descriptor

## Model Description
Molecular fingerprint based on language processing models using SMILES as text input
- Input: SMILES
- Output: Vector	(Vectorial molecular representation)
- Model type: Regressiom
- Mode of Training: Pretrained
- Training data: 861,000	(https://paperswithcode.com/dataset/moleculenet)
- Experimentally validated: No

## Source code
This model was published by Shion H., Shoi S. and Hiroki U. SMILES Transformer: Pre-trained Molecular Fingerprint for Low Data Drug Discovery. *arXiv Labs* 2019. DOI: https://doi.org/10.48550/arXiv.1911.04738
- Code: https://github.com/DSPsleeporg/smiles-transformer
- Chedkpoints: https://github.com/DSPsleeporg/smiles-transformer/tree/master/smiles_transformer

## License
The GPL-v3 license applies to all parts of the repository that are not externally maintained libraries. This repository uses the externally maintained library "smiles-transformers", located at `/model` and licensed under a MIT License

## History
- This model was downloaded on September 28, 2021
